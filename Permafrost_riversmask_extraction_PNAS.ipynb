{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "upset-diagnosis",
   "metadata": {},
   "source": [
    "\n",
    "# River masks Semi-authomatic Multi-Temporal extraction from Landsat SR images usign Google Earth Engine"\n",
    
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-pledge",
   "metadata": {},
   "source": [
    "### Niccolò Ragno, Riccardo Bonanomi, Marta Crivellaro, Alfonso Vitti, Guido Zolezzi and Marco Tubino\n",
    "* Publication corresponding Author: Niccolò Ragno,  niccolo.ragno@unitn.it\n",
    "* GEE code corresponding Author: Marta Crivellaro,  marta.crivellaro@unitn.it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e238c30-9946-4565-a138-23b468ca74a5",
   "metadata": {},
   "source": [
    "GEE Python installation: https://developers.google.com/earth-engine/guides/python_install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "complimentary-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries import\n",
    "import os, sys, glob, math,subprocess,tarfile,shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "from functions import ndvi,mndwi,addindex,areaImg,maxValue,ndviMap,mndwiMap\n",
    "# Installs geemap package\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    import geemap\n",
    "except ImportError:\n",
    "    print('Installing geemap ...')\n",
    "    subprocess.check_call([\"python\", '-m', 'pip', 'install', 'geemap'])\n",
    "import ee\n",
    "import geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e332d34a-4178-402c-9acd-699cdd0374ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc1ecf5-41e6-43b5-875b-5919968b0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-thanksgiving",
   "metadata": {},
   "source": [
    "### Create an interactive map\n",
    "The default basemap is _Google Maps_. Additional basemaps can be added using the ``Map.add_basemap()`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pending-beast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "Map = geemap.Map(center=[19.76,40.41], zoom=22)\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d64790-4b5c-481c-9067-fa3027331103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2144982fef34f7eaac5bf18b86abddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[19.76, 40.41], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(childre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1 - Define region(S) of interest (roi) as rectangular extents\n",
    "\n",
    "Selawick = ee.Geometry.Polygon([\n",
    "    [[-159.015607, 66.524316],\n",
    "     [-159.015607, 66.632938],\n",
    "     [-159.814012,66.632938],\n",
    "     [-159.814012,66.524316],\n",
    "     [-159.015607, 66.524316]]])#EPSG: 32604 Selawick Alaska\n",
    "\n",
    "fcGeom = Selawick\n",
    "roi = fcGeom \n",
    "Map.centerObject(roi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-illustration",
   "metadata": {},
   "source": [
    "Standardise band names, merge Landsat data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "earlier-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardise band names, merge Landsat data:\n",
    "bn8 = ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B6', 'SR_QA_AEROSOL', 'SR_B5', 'SR_B7', 'QA_PIXEL']\n",
    "bn7 = ['SR_B1', 'SR_B1', 'SR_B2', 'SR_B3', 'SR_B5', 'SR_CLOUD_QA', 'SR_B4', 'SR_B7','QA_PIXEL']\n",
    "bn5 = ['SR_B1', 'SR_B1', 'SR_B2', 'SR_B3', 'SR_B5', 'SR_CLOUD_QA', 'SR_B4', 'SR_B7','QA_PIXEL']\n",
    "#standard bans:\n",
    "bnL = ['uBlue', 'Blue', 'Green', 'Red', 'Swir1', 'BQA', 'Nir', 'Swir2','qa_pixel']\n",
    "\n",
    "## defining cloudmask function for landsat 7 and 8 only\n",
    "# This function masks the input with a threshold on the simple cloud score.\n",
    "# Observe that the input to simpleCloudScore() is a single Landsat TOA scene. \n",
    "# Also note that simpleCloudScore() adds a band called ‘cloud’ to the input image. \n",
    "# The cloud band contains the cloud score from 0 (not cloudy) to 100 (most cloudy).\n",
    "def cloudMask(img):\n",
    "    cloudscore = ee.Algorithms.Landsat.simpleCloudScore(img).select('cloud')\n",
    "    return img.updateMask(cloudscore.lt(10))\n",
    "\n",
    "def maskClouds(image):\n",
    "    \n",
    "    cloudShadowBitMask = (1 << 3)\n",
    "    cloudsBitMask = (1 << 5)\n",
    "    \n",
    "    qa = image.select('qa_pixel')\n",
    "    mask = (qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(qa.bitwiseAnd(cloudsBitMask).eq(0)))\n",
    "    \n",
    "    return image.updateMask(mask)\n",
    "\n",
    "#calling LS Surface Reflectance image collections \n",
    "ls5 = ee.ImageCollection(\"LANDSAT/LT05/C02/T1_L2\").filter(ee.Filter.lt('CLOUD_COVER',15)).select(bn5, bnL)\n",
    "ls7 = (ee.ImageCollection(\"LANDSAT/LE07/C02/T1_L2\")  \\\n",
    "  .map(cloudMask)  \\\n",
    "  .filterDate('1999-04-15', '2003-05-30')  \\\n",
    "  .select(bn7, bnL))\n",
    "ls8 = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\").filter(ee.Filter.lt('CLOUD_COVER', 15)).select(bn8, bnL)\n",
    "#merging LS 5 and 8 dataset\n",
    "ls = ls5.merge(ls8).sort('system:start', True).filter(ee.Filter.calendarRange(5,9,'month'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4c92f4c-2058-4cec-9589-5d5dc8326428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions definition\n",
    "def ErosDil(image):\n",
    "    kernel = ee.Kernel.square(2)\n",
    "    opened = image.focalMin(kernel=kernel, iterations=2).focalMax(kernel=kernel, iterations=2)\n",
    "    return opened\n",
    "\n",
    "def ClassifyWater(imgIn, method = 'Jones2019'):\n",
    "    if method == 'Jones2019':\n",
    "        from functions_waterClassification_Jones2019median import ClassifyWaterJones2019\n",
    "        return(ClassifyWaterJones2019(imgIn))\n",
    "    elif method == 'Zou2018':\n",
    "        from functions_waterClassification_Zou2018median import ClassifyWaterZou2018\n",
    "        return(ClassifyWaterZou2018(imgIn))\n",
    "    \n",
    "def RGBtoHSV (Image):\n",
    "    sat = Image.select(['Red','Green','Blue']).divide(65455).rgbToHsv().select(['saturation'])\n",
    "    return Image.addBands(sat)\n",
    "\n",
    "def histogram(image):\n",
    "    # Compute the histogram of the NIR band.  The mean and variance are only FYI.\n",
    "    polygon = ee.Geometry(image.geometry())\n",
    "    histogram = image.reduceRegion(\n",
    "        **{\n",
    "            'reducer': ee.Reducer.histogram(255, 2),\n",
    "            'geometry': polygon,\n",
    "            'scale': 15,\n",
    "            'bestEffort': True,\n",
    "        }\n",
    "    )\n",
    "    return histogram\n",
    "\n",
    "# Return the DN that maximizes interclass variance in B5 (in the region).\n",
    "def otsu(histogram):\n",
    "    counts = ee.Array(ee.Dictionary(histogram).get('histogram'))\n",
    "    means = ee.Array(ee.Dictionary(histogram).get('bucketMeans'))\n",
    "    size = means.length().get([0])\n",
    "    total = counts.reduce(ee.Reducer.sum(), [0]).get([0])\n",
    "    sum = means.multiply(counts).reduce(ee.Reducer.sum(), [0]).get([0])\n",
    "    mean = sum.divide(total)\n",
    "\n",
    "    indices = ee.List.sequence(1, size)\n",
    "\n",
    "    # Compute between sum of squares, where each mean partitions the data.\n",
    "\n",
    "    def func_xxx(i):\n",
    "        aCounts = counts.slice(0, 0, i)\n",
    "        aCount = aCounts.reduce(ee.Reducer.sum(), [0]).get([0])\n",
    "        aMeans = means.slice(0, 0, i)\n",
    "        aMean = (\n",
    "            aMeans.multiply(aCounts)\n",
    "            .reduce(ee.Reducer.sum(), [0])\n",
    "            .get([0])\n",
    "            .divide(aCount)\n",
    "        )\n",
    "        bCount = total.subtract(aCount)\n",
    "        bMean = sum.subtract(aCount.multiply(aMean)).divide(bCount)\n",
    "        return aCount.multiply(aMean.subtract(mean).pow(2)).add(\n",
    "            bCount.multiply(bMean.subtract(mean).pow(2))\n",
    "        )\n",
    "\n",
    "    bss = indices.map(func_xxx)\n",
    "\n",
    "    # Return the mean value corresponding to the maximum BSS.\n",
    "    return means.sort(bss).get([-1])\n",
    "\n",
    "def extract_ac(imagesat,imagemndwi, t_sat, t_mndwi):\n",
    "    ac = imagesat.select('saturation_median').gte(t_sat).Or(imagemndwi.select('mndwi_median').gte(t_mndwi)).selfMask()\n",
    "    return ee.Image(ac)\n",
    "\n",
    "def stdLocal (image, roi): \n",
    "    geom = roi.geometry()\n",
    "    std_value = image.clip(geom).reduceRegion(**{\n",
    "        'reducer': ee.Reducer.stdDev(),\n",
    "        'geometry': geom,\n",
    "        'scale': 30,\n",
    "        'maxPixels': 1e12,\n",
    "        'tileScale': 16\n",
    "    })\n",
    "    return std_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "003ef720-11a5-4382-9087-325248283d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERONA MALIK FILTER\n",
    "# Perona malik filter\n",
    "# I(n+1, i, j) = I(n, i, j) + Lambda * (cN * dN(I) + cS * dS(I) + cE * dE(I), cW * dW(I))\n",
    "#**\n",
    "#Perona-Malik (anisotropic diffusion) convolution\n",
    "#by Gennadii Donchyts see https://groups.google.com/forum/#!topic/google-earth-engine-developers/a9W0Nlrhoq0\n",
    "#I(n+1, i, j) = I(n, i, j) + lambda * (cN * dN(I) + cS * dS(I) + cE * dE(I), cW * dW(I))\n",
    "#iter: Number of interations to apply filter\n",
    "#K: kernal size\n",
    "#method: choose method 1 (default) or 2\n",
    "# Returns: image \n",
    "#\n",
    "def peronaMalikFilter(I, iter, K, method, l):\n",
    "    dxW = ee.Kernel.fixed(3, 3, [[ 0,  0,  0], [ 1, -1,  0], [ 0,  0,  0]])\n",
    "    dxE = ee.Kernel.fixed(3, 3, [[ 0,  0,  0], [ 0, -1,  1], [ 0,  0,  0]])\n",
    "    dyN = ee.Kernel.fixed(3, 3, [[ 0,  1,  0], [ 0, -1,  0], [ 0,  0,  0]])\n",
    "    dyS = ee.Kernel.fixed(3, 3, [[ 0,  0,  0], [ 0, -1,  0], [ 0,  1,  0]])\n",
    "    \n",
    "    Lambda = l \n",
    "    \n",
    "    k1 = ee.Image(-1.0/K)\n",
    "    k2 = ee.Image(K).multiply(ee.Image(K))\n",
    "    \n",
    "    for i in range(0, iter):\n",
    "        dI_W = I.convolve(dxW)\n",
    "        dI_E = I.convolve(dxE)\n",
    "        dI_N = I.convolve(dyN)\n",
    "        dI_S = I.convolve(dyS)\n",
    "        \n",
    "        if method == 1:\n",
    "            cW = dI_W.multiply(dI_W).multiply(k1).exp()\n",
    "            cE = dI_E.multiply(dI_E).multiply(k1).exp()\n",
    "            cN = dI_N.multiply(dI_N).multiply(k1).exp()\n",
    "            cS = dI_S.multiply(dI_S).multiply(k1).exp()\n",
    "        elif method == 2:\n",
    "            cW = ee.Image(1.0).divide(ee.Image(1.0).add(dI_W.multiply(dI_W).divide(k2)))\n",
    "            cE = ee.Image(1.0).divide(ee.Image(1.0).add(dI_E.multiply(dI_E).divide(k2)))\n",
    "            cN = ee.Image(1.0).divide(ee.Image(1.0).add(dI_N.multiply(dI_N).divide(k2)))\n",
    "            cS = ee.Image(1.0).divide(ee.Image(1.0).add(dI_S.multiply(dI_S).divide(k2)))\n",
    "        I = I.add(ee.Image(Lambda).multiply(cN.multiply(dI_N).add(cS.multiply(dI_S)).add(cE.multiply(dI_E)).add(cW.multiply(dI_W))))\n",
    "    \n",
    "    return I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882a04f9-56d1-454b-8590-3add989d15cc",
   "metadata": {},
   "source": [
    "### Cycle on years to export annual domain mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e512ca3d-3c0c-42f8-bea1-2a8081476b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1986 Export Done!\n",
      "1986 &diff -86.17567419629782\n",
      "1986params:\n",
      "1986 Done!\n",
      "2006 Export Done!\n",
      "2006 &diff -95.47277906564369\n",
      "2006params:\n",
      "2006 Done!\n"
     ]
    }
   ],
   "source": [
    "dates = [1986,2015,2019,2021]\n",
    "ACy = {}\n",
    "data= []\n",
    "\n",
    "roi = fcGeom\n",
    "for i in dates:\n",
    "    sDate_T1 = str(i)+\"-05-01\"; \n",
    "    eDate_T1 = str(i)+\"-09-30\";\n",
    "    #Sort by:  roi, date:\n",
    "    collection= ls \\\n",
    "        .filterBounds(roi) \\\n",
    "        .sort('system:start', True) \\\n",
    "        .filterDate(sDate_T1,eDate_T1)\n",
    "\n",
    "    # Create a list of image objects.\n",
    "    imageList = collection.toList(100);\n",
    "    Collection = collection.map(ndviMap).map(mndwiMap).map(RGBtoHSV)\n",
    "    median = Collection.reduce(ee.Reducer.median())#.reproject(ee.Projection('EPSG:32604')) #qui è bene cambiare con la proiezione WGS 84 UTM LOCALE\n",
    "    maxi = Collection.reduce(ee.Reducer.percentile([90]))#.reproject(ee.Projection('EPSG:32604'))\n",
    "    mini = Collection.reduce(ee.Reducer.min())#.reproject(ee.Projection('EPSG:32604'))\n",
    "\n",
    "    ndvimap_median=median.select('ndvi_median').clip(roi)\n",
    "    ndvimap_90p=maxi.select('ndvi_p90').clip(roi)\n",
    "    mndwimap_median=median.select('mndwi_median').clip(roi)\n",
    "    \n",
    "    satmap_90p=maxi.select('saturation_p90').clip(roi)\n",
    "   \n",
    "    ndwimap_90p=maxi.select('mndwi_p90').clip(roi)\n",
    "\n",
    "\n",
    "    pm_mndwi_0_3 = peronaMalikFilter(mndwimap_median, 5, 2, 1, 0.3)\n",
    "  \n",
    "    otsu_mndwi = otsu(histogram(mndwimap_median).get('mndwi_median'))\n",
    "    otsu_sat = otsu(histogram(satmap_90p).get('saturation_p90'))\n",
    "    otsu_mndwiPM = otsu(histogram(pm_mndwi_0_3).get('mndwi_median'))\n",
    "    \n",
    "    veg1 = ndvimap_90p.select('ndvi_p90').gte(0.15)\n",
    "    water3 =  satmap_90p.gt(otsu_sat).Or(ee.Image(mndwimap_median.select('mndwi_median')\n",
    "                                                  .gte(otsu_mndwi)).And(veg1.lt(1)))\n",
    "\n",
    "    waterPM3 = satmap_90p.gt(otsu_sat).Or(pm_mndwi_0_3.select('mndwi_median')\n",
    "                                          .gte(otsu_mndwiPM)).And(veg1.lt(1))\n",
    "    #Export the images, specifying scale and region.\n",
    "    task = ee.batch.Export.image.toDrive(**{\n",
    "         'image': waterPM3.clip(fcGeom),\n",
    "         'description': 'Selawick'+str(i),\n",
    "         'folder':'Permafrost_rivermask',\n",
    "         'scale': 30,\n",
    "         'crs': 'EPSG:32604',\n",
    "         'region': fcGeom\n",
    "\n",
    "     })\n",
    "    task.start()\n",
    "    \n",
    "    task = ee.batch.Export.image.toDrive(**{\n",
    "         'image': water3.clip(fcGeom),\n",
    "         'description': 'Selawick'+str(i),\n",
    "         'folder':'Permafrost_rivermask',\n",
    "         'scale': 30,\n",
    "         'crs': 'EPSG:32604',\n",
    "         'region': fcGeom\n",
    "\n",
    "     })\n",
    "    task.start()\n",
    "\n",
    "    area_raw_N = areaImg(water3.remap(ee.List([0]),ee.List([1])))\n",
    "    area_pm_N = areaImg(waterPM3.remap(ee.List([0]),ee.List([1])))\n",
    "    # extract the value as a number\n",
    "    area_raw_number = area_raw_N.getNumber('remapped').getInfo()\n",
    "    area_pm_number = area_pm_N.getNumber('remapped').getInfo()\n",
    "    #dataframe with extracted areas and thresholds info creation and compiling\n",
    "    data.append(dict(zip(('year','area_raw_number','area_pm_number','%d','t_nmndwi','t_PMmndwi'),\n",
    "                         (str(i),area_raw_number,area_pm_number,(100*((area_raw_number-area_pm_number)/area_raw_number)),otsu_mndwi.getInfo(),otsu_mndwiPM.getInfo(),))))\n",
    "                \n",
    "    print(str(i)+' Export Done!')\n",
    "    print(str(i)+' &diff', (100*((area_raw_number-area_pm_number)/area_raw_number)))\n",
    "    print(str(i)+'params:')\n",
    "    print(str(i)+' Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "969ca477-3616-444c-9e88-843f677881c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>area_raw_number</th>\n",
       "      <th>area_pm_number</th>\n",
       "      <th>%d</th>\n",
       "      <th>t_nmndwi</th>\n",
       "      <th>t_PMmndwi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>1.777955e+09</td>\n",
       "      <td>5.293272e+09</td>\n",
       "      <td>-197.716864</td>\n",
       "      <td>-0.075316</td>\n",
       "      <td>-0.067019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991</td>\n",
       "      <td>5.610041e+09</td>\n",
       "      <td>6.193455e+09</td>\n",
       "      <td>-10.399455</td>\n",
       "      <td>-0.102547</td>\n",
       "      <td>-0.092328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>5.680065e+09</td>\n",
       "      <td>6.766941e+09</td>\n",
       "      <td>-19.134910</td>\n",
       "      <td>-0.142254</td>\n",
       "      <td>-0.134328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>3.404581e+09</td>\n",
       "      <td>5.238701e+09</td>\n",
       "      <td>-53.872094</td>\n",
       "      <td>-0.116658</td>\n",
       "      <td>-0.106486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>5.129936e+09</td>\n",
       "      <td>6.842760e+09</td>\n",
       "      <td>-33.388799</td>\n",
       "      <td>-0.130436</td>\n",
       "      <td>-0.121201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  area_raw_number  area_pm_number          %d  t_nmndwi  t_PMmndwi\n",
       "0  1985     1.777955e+09    5.293272e+09 -197.716864 -0.075316  -0.067019\n",
       "1  1991     5.610041e+09    6.193455e+09  -10.399455 -0.102547  -0.092328\n",
       "2  2007     5.680065e+09    6.766941e+09  -19.134910 -0.142254  -0.134328\n",
       "3  2015     3.404581e+09    5.238701e+09  -53.872094 -0.116658  -0.106486\n",
       "4  2020     5.129936e+09    6.842760e+09  -33.388799 -0.130436  -0.121201"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.to_csv('Selawick_stats.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
